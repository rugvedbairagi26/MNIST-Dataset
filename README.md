# MNIST-Dataset
🧠 MNIST Classifier from Scratch using NumPy
This project implements a simple 2-layer Neural Network in pure NumPy to classify handwritten digits from the MNIST dataset — without using any machine learning libraries like TensorFlow or PyTorch.
______________________________________________________________________________________________________________________________________________________________________________________________________

📂 Files
mnist_train.csv: MNIST training data in CSV format

mnist_test.csv (optional): MNIST test data in CSV format (for evaluation)

mnist_nn.py: Main Python script implementing the model

README.md: This file

______________________________________________________________________________________________________________________________________________________________________________________________________

🧱 Architecture
Input layer: 784 units (28×28 flattened image)

Hidden layer: 128 ReLU neurons

Output layer: 10 Softmax neurons (digits 0–9)

________________________________________________________________________________________________________________________________________________________________________________________________________

⚙️ Features
Stable Softmax: Avoids overflow issues

He Initialization: Improves convergence

One-Hot Encoding: Converts digit labels to one-hot vectors

Batch Gradient Descent: Learns from the full dataset per epoch

___________________________________________________________________________________________________________________________________________________________________________________________________________

📬 Author Rugved Bairagi B.E. CSE (2nd Year) | PCCOER | Aspiring AI Researcher

• 📧 rugvedbairagi26@email.com

• Rugvedbairagi264248@gmail.com

• 🔗 LinkedIn

• 🐦 X / Twitter



ReLU Activation: Non-linearity in hidden layer

Pure NumPy: No ML libraries used

_________________________________________________________________________________________________________________________________________________________________________________________________________
