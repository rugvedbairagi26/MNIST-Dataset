# MNIST-Dataset
ğŸ§  MNIST Classifier from Scratch using NumPy
This project implements a simple 2-layer Neural Network in pure NumPy to classify handwritten digits from the MNIST dataset â€” without using any machine learning libraries like TensorFlow or PyTorch.
______________________________________________________________________________________________________________________________________________________________________________________________________

ğŸ“‚ Files
mnist_train.csv: MNIST training data in CSV format

mnist_test.csv (optional): MNIST test data in CSV format (for evaluation)

mnist_nn.py: Main Python script implementing the model

README.md: This file

______________________________________________________________________________________________________________________________________________________________________________________________________

ğŸ§± Architecture
Input layer: 784 units (28Ã—28 flattened image)

Hidden layer: 128 ReLU neurons

Output layer: 10 Softmax neurons (digits 0â€“9)

________________________________________________________________________________________________________________________________________________________________________________________________________

âš™ï¸ Features
Stable Softmax: Avoids overflow issues

He Initialization: Improves convergence

One-Hot Encoding: Converts digit labels to one-hot vectors

Batch Gradient Descent: Learns from the full dataset per epoch

___________________________________________________________________________________________________________________________________________________________________________________________________________

ğŸ“¬ Author Rugved Bairagi B.E. CSE (2nd Year) | PCCOER | Aspiring AI Researcher

â€¢ ğŸ“§ rugvedbairagi26@email.com

â€¢ Rugvedbairagi264248@gmail.com

â€¢ ğŸ”— LinkedIn

â€¢ ğŸ¦ X / Twitter



ReLU Activation: Non-linearity in hidden layer

Pure NumPy: No ML libraries used

_________________________________________________________________________________________________________________________________________________________________________________________________________
